import aiohttp
import asyncio
from datetime import datetime, timedelta
import pytz
import re

async def test_scraping():
    async with aiohttp.ClientSession() as session:
        url = "https://www.mexc.co/vi-VN/newlisting"
        print(f"ğŸ” Scraping: {url}\n")
        
        try:
            async with session.get(url, timeout=15) as r:
                print(f"âœ… Status: {r.status}\n")
                
                if r.status != 200:
                    print(f"âŒ HTTP Error: {r.status}")
                    return
                
                html = await r.text()
                print(f"ğŸ“„ HTML Length: {len(html)} characters\n")
                
                # LÆ°u HTML ra file Ä‘á»ƒ xem
                with open("mexc_newlisting.html", "w", encoding="utf-8") as f:
                    f.write(html)
                print("ï¿½ Saved HTML to mexc_newlisting.html\n")
                
                # TÃ¬m cÃ¡c tá»« khÃ³a liÃªn quan
                keywords = ["niÃªm yáº¿t", "listing", "KAIROS", "MINDHIVE", "vcoinName", "onlineTime"]
                for kw in keywords:
                    count = html.count(kw)
                    print(f"  '{kw}': {count} occurrences")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()

asyncio.run(test_scraping())
