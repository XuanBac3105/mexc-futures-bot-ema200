import aiohttp
import asyncio
from bs4 import BeautifulSoup
from datetime import datetime
import pytz
import re

async def test_scrape_announcements():
    async with aiohttp.ClientSession() as session:
        url = "https://www.mexc.co/vi-VN/announcements/new-listings"
        print(f"üîç Scraping: {url}\n")
        
        try:
            async with session.get(url, timeout=15) as r:
                print(f"‚úÖ Status: {r.status}\n")
                
                if r.status != 200:
                    print(f"‚ùå HTTP Error: {r.status}")
                    return
                
                html = await r.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                print(f"üìÑ HTML Length: {len(html)} characters\n")
                
                # T√¨m t·∫•t c·∫£ announcement items
                # Th·ª≠ nhi·ªÅu selector
                selectors = [
                    'a[href*="/announcements/"]',  # Links to announcements
                    'div.announcement-item',
                    'article',
                    'li',
                ]
                
                results = []
                
                # T√¨m pattern CH·ªà FUTURES - c·∫£i thi·ªán
                # Pattern 1: "ƒê·∫ßu ti√™n tr√™n th·ªã tr∆∞·ªùng: MEXC ni√™m y·∫øt X (SYMBOL) USDT-M Futures v√†o HH:MM DD/MM/YYYY"
                # Pattern 2: "ni√™m y·∫øt X (SYMBOL) ... Futures ... HH:MM DD/MM/YYYY"
                
                pattern1 = r'ni√™m y·∫øt\s+([\w\s]+?)\s*\(([A-Z0-9]+)\)\s+(?:USDT-M\s+)?[Ff]utures.*?(\d{2}:\d{2}\s+\d{2}/\d{2}/\d{4})'
                
                # T√¨m trong to√†n b·ªô text
                text_content = soup.get_text()
                matches = re.findall(pattern1, text_content, re.DOTALL)
                
                # L√†m s·∫°ch matches - lo·∫°i b·ªè text d√†i b·∫•t th∆∞·ªùng
                clean_matches = []
                for full_name, symbol, time_str in matches:
                    # Ch·ªâ gi·ªØ t√™n coin ng·∫Øn g·ªçn (< 50 k√Ω t·ª±)
                    full_name = full_name.strip()
                    if len(full_name) < 50 and not '\n' in full_name:
                        clean_matches.append((full_name, symbol, time_str))
                
                matches = clean_matches
                
                print(f"üéØ Found {len(matches)} FUTURES announcements:\n")
                
                for idx, (full_name, symbol, time_str) in enumerate(matches[:10], 1):
                    print(f"{idx}. üöÄ Futures Coin: {symbol.strip()}")
                    print(f"   Full name: {full_name.strip()}")
                    print(f"   Time: {time_str}")
                    
                    # Parse th·ªùi gian: "21:10 14/11/2025"
                    try:
                        vn_tz = pytz.timezone('Asia/Ho_Chi_Minh')
                        dt = datetime.strptime(time_str, "%H:%M %d/%m/%Y")
                        dt = vn_tz.localize(dt)
                        print(f"   Parsed: {dt}")
                    except Exception as e:
                        print(f"   Parse error: {e}")
                    
                    print()
                
                # Kh√¥ng c·∫ßn pattern 2 n·ªØa v√¨ ch·ªâ l·∫•y Futures
                
                # L∆∞u HTML ƒë·ªÉ debug
                with open("mexc_announcements.html", "w", encoding="utf-8") as f:
                    f.write(html)
                print("\nüíæ Saved HTML to mexc_announcements.html")
                
        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()

asyncio.run(test_scrape_announcements())
